{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on using virtual environments with Jupyter. First install `virtualenv`:\n",
    "```\n",
    "pip install --user virtualenv\n",
    "```\n",
    "Then create your virtual environment:\n",
    "```\n",
    "python -m venv langpine\n",
    "```\n",
    "After you have created your virtual environment, you can activate the virtual environment with:\n",
    "```\n",
    "source langpine/bin/activate\n",
    "```\n",
    "Next, install ipykernel which provides the IPython kernel for Jupyter:\n",
    "```\n",
    "pip install ipykernel\n",
    "```\n",
    "Next you can add your virtual environment to Jupyter by typing:\n",
    "```\n",
    "python -m ipykernel install --name=langpine\n",
    "```\n",
    "\n",
    "It should now be possible to use the `langpine` environment in Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qngtkIocTgB4",
    "outputId": "64f906dd-90a3-4c28-aa0f-0b19c965aa2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/thomasclowers/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pylibmagic\n",
    "import magic\n",
    "import pinecone\n",
    "\n",
    "import langchain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "import magic\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "PINECONE_API_KEY = 'caf644e7-6194-4e46-9bed-f6631b69b6c8'\n",
    "PINECONE_API_ENV = 'us-west4-gcp-free'\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "P6qpYSP3g10c"
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"./Some_thoughts_on_education.pdf\")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VzbtJ8diiqwu",
    "outputId": "477a5259-be8c-4060-afcf-99ceb301d94c"
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "qQ_olMwji0pR"
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "gTmuLUDsi8aN",
    "outputId": "62d9d405-6002-483f-98b5-99cdfcefba19"
   },
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_API_ENV\n",
    ")\n",
    "index_name = \"mlqai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinecone.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = pinecone.list_indexes()\n",
    "# len(indexes) < 1 || \n",
    "if index_name not in indexes:\n",
    "    pinecone.create_index(index_name, dimension=1536)\n",
    "else:\n",
    "    print(\"Index already present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' An Odyssean education is an approach to education proposed by Nobel-winning physicist Murray Gell Mann. It focuses on synthesizing maths and the natural sciences, the social sciences, and the humanities and arts into crude, trans-disciplinary, integrative thinking about complex systems. It is aimed mainly at 15-25 year-olds and includes courses like The Big History Project, Berkeley’s ‘Physics for Future Presidents’, and programming. It also includes training in managing complex projects and using modern tools such as agent-based models. It is focused on humans’ biggest and most important problems and aims to train synthesisers who have a crude but useful grasp of connections between the biggest challenges, the ability to take better decisions and adapt fast to failures, and an evolutionary perspective on complex systems and institutional design.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "query = \"Tell me about the elements of Odyssean education\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "langpine",
   "language": "python",
   "name": "langpine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
